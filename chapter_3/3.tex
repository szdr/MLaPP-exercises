\documentclass{jsarticle}
\usepackage{amsmath, amssymb}
\begin{document}
\section*{Exercise 3.1 MLE for the Bernoulli/ binomial model}
\begin{align}
\frac{d}{d\theta}p(D|\theta) & = \frac{d}{d\theta}(\theta^{N_1}(1-\theta)^{N_0})\\
& = N_1 \theta^{N_1-1}(1-\theta)^{N_0}-N_0\theta^{N_1}(1-\theta)^{N_01}\\
& = \theta^{N_1-1}(1-\theta)^{N_0-1}(N_1(1-\theta)-N_0\theta) \\
& = \theta^{N_1-1}(1-\theta)^{N_0-1}(N_1-N\theta)\\
\therefore \theta_{\rm MLE} & =\frac{N_1}{N}
\end{align}

\section*{Exercise 3.2 Marginal likelihood for the Beta-Bernoulli model}
\begin{align}
p(D) & = \frac{[(\alpha_1)\cdots(\alpha_1+N_1-1)][(\alpha_0)\cdots(\alpha_0+N_0-1)]}{(\alpha)\cdots(\alpha + N - 1)}\\
& = \frac{[(\alpha_1)\cdots(\alpha_1+N_1-1)][(\alpha_0)\cdots(\alpha_0+N_0-1)]}{(\alpha_1+\alpha_0)\cdots(\alpha_1 + \alpha_0 + N - 1)}\\
& = \frac{\Gamma(\alpha_1+\alpha_0)}{\Gamma(\alpha_1+\alpha_0+N)}[(\alpha_1)\cdots (\alpha_1+N_1-1)][(\alpha_0)\cdots(\alpha_0+N_0-1)]\\
& = \frac{\Gamma(\alpha_1+\alpha_0)}{\Gamma(\alpha_1+\alpha_0+N)}\frac{\Gamma(\alpha_1+N_1)}{\Gamma(\alpha_1)}\frac{\Gamma(\alpha_0+N_0)}{\Gamma(\alpha_0)}\\
& = \frac{\Gamma(\alpha_1+N_1)\Gamma(\alpha_0+N_0)}{\Gamma(\alpha_1+\alpha_0+N)}\frac{\Gamma(\alpha_1+\alpha_0)}{\Gamma(\alpha_1)\Gamma(\alpha_0)}
\end{align}

\section*{Exercise 3.3 Posterior prdictive for Beta-Binomial model}
\begin{align}
Bb(1|\alpha_1',\alpha_0',1) & = \frac{B(1+\alpha_1',1-1+\alpha_0')}{B(\alpha_1',\alpha_0')} \begin{pmatrix} 1 \\ 1 \end{pmatrix} \\
& = \frac{B(1+\alpha_1', \alpha_0')}{B(\alpha_1',\alpha_0')}\\
& = \frac{\Gamma(\alpha_1'+\alpha_0')}{\Gamma(\alpha_1')\Gamma(\alpha_0')}\frac{\Gamma(1+\alpha_1')\Gamma(\alpha_0')}{\Gamma(1+\alpha_1'+\alpha_0')}\\
& = \frac{\Gamma(\alpha_1'+\alpha_0')}{\Gamma(\alpha_1')\Gamma(\alpha_0')}\frac{\alpha_1'\Gamma(\alpha_1')\Gamma(\alpha_0')}{(\alpha_1'+\alpha_0')\Gamma(\alpha_1'+\alpha_0')}\\
& = \frac{\alpha_1'}{\alpha_1'+\alpha_0'}
\end{align}

\section*{Exercise 3.4 Beta updating from censored likelihood}
\begin{align}
p(\theta,X<3) & = p(\theta)p(X<3|\theta)\\
& = p(\theta)(\sum_{k=0}^{2}p(X=k|\theta))\\
& = p(\theta)(\sum_{k=0}^{2}\theta^k(1-\theta)^{(5-k)})\\
& = Beta(\theta|1,1)(\sum_{k=0}^{2}\theta^k(1-\theta)^{(5-k)})\\
& = \sum_{k=0}^{2}\theta^k(1-\theta)^{(5-k)}
\end{align}

\section*{Exercise 3.5 Uninformative prior for log-odds ratio}
\begin{align}
p(\theta) & = p(\phi)|\frac{d\phi}{d\theta}|\\
& = p(\phi)\theta^{-1}(1-\theta)^{-1}\\
& \propto Beta(\theta|0,0)\ (\because p(\phi)\propto 1)
\end{align}

\section*{Exercise 3.6 MLE for the Poisson distribution}
\begin{align}
D & = \{x_1, x_2, \dots, x_N\}\\
p(D|\lambda) & = \Pi_{i=1}^{N}Poi(x_i|\lambda)\\
& = e^{-N\lambda}\frac{\lambda^{\sum_{i=1}^{N}x_i}}{\Pi_{i=1}^{N}(x_i!)}\\
\log p(D|\lambda) & = -N\lambda + \sum_{i=1}^{N}x_i\log \lambda - \sum_{i=1}^{N}\log x_i!\\
\frac{\partial}{\partial \lambda}\log p(D|\lambda) & = -N + \frac{1}{\lambda}\sum_{i=1}^{N}x_i\\
\therefore\lambda_{MLE} & =\frac{1}{N}\sum_{i=1}^{N}x_i
\end{align}

\section*{Exercise 3.7 Bayesian analysis of the Poisson distribution}
\subsection*{(a)}
\begin{align}
p(\lambda|D) & \propto p(\lambda)p(D|\lambda)\\
& \propto \lambda^{a-1}e^{-\lambda b}e^{-N\lambda}\frac{\lambda^{\sum_{i=1}^{N}x_i}}{\Pi_{i=1}^{N}(x_i!)}\\
& = e^{-\lambda(N+b)}\frac{\lambda^{\sum_{i=1}^{N}x_i}}{\Pi_{i=1}^{N}(x_i!)}\\
& \propto Ga(\lambda|a + \sum_{i=1}^{N}x_i, b + N)
\end{align}
\subsection*{(b)}
\begin{align}
\frac{a+\sum_{i=1}^{N}x_i}{b+N} & \rightarrow \frac{1}{N}\sum_{i=1}^{N}x_i\\
& = \lambda_{MLE}
\end{align}

\section*{Exercise 3.8 MLE for the uniform distribution}
\subsection*{(a)}
\begin{align}
D & = \{x_1, \dots, x_N\} \\
p(D|a) & = \Pi_{i=1}^{N}\frac{1}{2a}I(x_i\in [-a, a])
\end{align}
If $\forall i\ -a \leq x_i \leq a$, then $p(D|a)=\frac{1}{(2a)^n}$.
More smaller $a$, more larger $p(D|a)$.

$\hat{a}=\max \{|x_1|,\dots, |x_N| \}$

\subsection*{(b)}
\begin{align}
p(x_{n+1}|\hat{a}) & = \frac{1}{2\hat{a}}I(x_{n+1}\in[-\hat{a}, \hat{a}])\\
& = \begin{cases}
0 & (x_{n+1}\notin [-\hat{a}, \hat{a}])\\
\frac{1}{2\hat{a}} & (x_{n+1}\in [-\hat{a}, \hat{a}])
\end{cases} 
\end{align}

\subsection*{(c)}
If we use MLE approach, the probability between $-\hat{a}$ and $\hat{a}$ is 0.
Bayesian approach with introducing a wide range prior is better.

\section*{Exercise 3.9 Bayesian analysis of the uniform distribution}
\begin{align}
p(\theta|D) & = \frac{p(D,\theta)}{p(D)}\\
& = \begin{cases}
\frac{(N+K)b^N}{K}p(D,\theta) & (m \leq b) \\
\frac{(N+K)m^{N+K}}{Kb^K}p(D, \theta) & (m > b)
\end{cases} \\
& = \begin{cases}
\frac{(N+K)b^{N+K}}{\theta^{N+K+1}}I(\theta \geq \max(D,b)) & (m \leq b)\\
\frac{(N+K)m^{N+K}}{\theta^{N+K+1}}I(\theta \geq \max(D,b)) & (m > b)
\end{cases}\\
& = (N+K)\{\max(D,b) \}^{N+K}\theta^{-(N+K+1)}I(\theta \geq \max (D,b)) \\
& = {\rm Pareto}(\theta|N+K,\max(D,b))
\end{align}

\section*{Exercise 3.10 Taxicab (tramcar) problem}
\subsection*{(a)}
\begin{align}
p(\theta|\{100\}) & = {\rm Pareto}(\theta|1,100)\\
& = 100 \theta^{-2}I(\theta \geq 100)
\end{align}
\subsection*{(b)}
\subsubsection*{mean}
not exist
\subsubsection*{mode}
100
\subsubsection*{median}
\begin{align}
\int_{100}^{x}100\theta^{-2}I(\theta \geq 100)d\theta & = \frac{1}{2}\\
100\int_{100}^{x}\theta^{-2}d\theta & = \frac{1}{2}\\
-100[\frac{1}{\theta}]_{100}^{x} & = \frac{1}{2}\\
\frac{1}{x} - \frac{1}{100} & = - \frac{1}{200}\\
x & = 200
\end{align}
\subsection*{(c)}
\begin{align}
p(D'|D,\alpha) & = \int_{\theta}p(D'|\theta)p(\theta|D,\alpha)d\theta\\
& = \int_{\theta}U(x|0,\theta){\rm Pareto}(\theta|1,m)d\theta\\
& = \int_{\theta}\frac{1}{\theta}I[0\leq x \leq \theta]m\theta^{-2}I(\theta \geq m)d\theta \\
& = m \int_{\theta}\theta^{-3}I[0\leq x \leq \theta]I[\theta \geq m]d\theta \\
& = m[-\frac{1}{2}\theta^{-2}]_{\max(x,m)}^{\infty}\\
& = \frac{m}{2\{\max(x,m) \}^2}
\end{align}
\subsection*{(d)}
\begin{align}
p(x=100|D,\alpha) & = \frac{1}{200}\\
p(x=50|D,\alpha) & = \frac{1}{200} \\
p(x=150|D,\alpha) & = \frac{100}{2 \cdot 150^2} = \frac{1}{450}
\end{align}
\subsection*{(e)}
\begin{itemize}
	\item More observations, more accurate.
	\item Thy hyper-parameter of prior should be set by other information.
\end{itemize}
\end{document}